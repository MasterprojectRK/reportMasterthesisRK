\section{Advancing predictions of Hi-C interaction matrices}
In the following subsections, two conceptually different approaches towards the goal of the thesis,
predicting Hi-C matrices from ChIP-seq data, will be explored.
While the first approach is a dense neural network based on work by Farr\'e et al. \cite{Farre2018a},
the second is a novel method based on conditional generative adversarial networks.

\subsection{Dense Neural Network approach}\label{sec:DNNapproach}
In their 2008 paper \cite{Farre2018a}, Pau Farr\'e, Alexandre Heurtau, Olivier Cuvier and Eldon Emberly
propose a combination of a 1D convolutional filter with a three-layer dense neural network 
which already fulfills most goals of this thesis with some exceptions regarding data formats and preprocessing.
This thesis tries to build on the success of their method by extending the comparatively simple neural network
in various ways, modifying the binsizes of the Hi-C matrices and changing the learning process.
As a start, the basic network has been rebuilt and used on well-known data from human cell lines GM12878 and K562.

\subsubsection{Basic network setup} \label{sec:improve:basicNetwork}
The basic network setup taken over from Farr\'e et al. \cite{Farre2018a} is shown in simplied form in \cref{fig:improve:priciple_basic_dnn},
see \cref{sec:methods:basicSetup} for technical details.
\begin{figure}[hbp]
    \small
    \centering
    \resizebox{\textwidth}{!}{
    \import{figures/}{explanation_dnn_hic.pdf_tex}}
    \caption{Principle of basic dense neural network}
    \label{fig:improve:priciple_basic_dnn}
\end{figure}

Since the network implements a supervised learning technique,
it requires two kinds of inputs for training -- ChIP-seq data of the chosen chromatin factors and
target Hi-C matrices for each training chromosome.
However, it is generally infeasible to learn Hi-C matrices for complete chromosomes at once with machine learning approaches, 
because the latter heavily depend on availability of training data.

The target matrices are thus taken as submatrices of size $w \times w$ 
with fixed windowsize $w$, centered at the diagonal of the 
original Hi-C matrices, \cref{fig:improve:priciple_basic_dnn} top.
The ChIP-seq data is taken as $3w \times n$ subarray of the original array,
whereby the middle $w$ bins are aligned with the position of the submatrix,
the first $w$ bins correspond to the left flanking region and the last $w$ bins correspond to 
the right flanking region of the current submatrix region, \cref{fig:improve:priciple_basic_dnn} bottom. 
Training samples are then obtained from the input data by sliding 
the input windows along the diagonal of the target Hi-C matrix. 
For the technical details of the sample generation process, see \cref{sec:methods:sample_gen}.

Within the network, a 1D convolutional filter compresses the $3w \times n$ input arrays to 1D vectors
of size $3w \times 1$, and four dense layers further process the compressed input, \cref{fig:improve:priciple_basic_dnn} middle.
The number of neurons in the last dense layer corresponds to the number of bins
in the upper triangular part of the target submatrix, i.\,e. it consists of $(w \cdot (w+1))/2$ neurons,
exploiting the symmetry of Hi-C matrices. 
For implementation details, please refer to \cref{sec:methods:basicSetup}.

Training of the network is performed by minimizing the mean squared error of the predicted matrix
versus the target Hi-C matrix using stochastic gradient descent.
The technical details are also given in \cref{sec:methods:basicSetup}

Farr\'e et al. propose a windowsize of $w=80$ at $b_{feat} = b_{mat} = \SI{10}{\kilo\bp}$.
However, larger binsizes of $b_{feat} = b_{mat} = \SI{25}{\kilo\bp}$ were found beneficial for 
most of the data used throughout this master thesis.
Additionally, larger binsizes allow for a higher coverage of the target matrix at the same windowsize,
because obviously $10\, w < 25\, w$.
Results for both binsize 10 and \SI{25}{\kilo\bp} are shown in \cref{sec:initialDNNresults}.

The network shown above is quite simple, and immediately offers some opportunities
for expansion, partially already proposed in the original paper \cite{Farre2018a}.
These will be explored below.

\subsubsection{Modifying the convolutional part of the network}
One starting point for modifying the neural network is its convolutional part.

With only a single 1D convolutional filter in one layer, the network might have difficulties capturing complex relationships 
between Hi-C interaction counts and more than one of the chromatin features.
For this reason, an extended ``longer'' network was created, 
comprising three 1D convolutional filter layers with 16, 8 and 4 filters, respectively.
This is still a comparatively low number of layers and filters,
but the choice seemed justified in order to avoid overfitting to the low-dimensional input.

Next, a ``wider'' network was created, featuring the same setup as the basic network
except the width of the filter kernel, which was set to 4 instead of 1.
The idea here is to allow the network to capture correlations between Hi-C interaction counts
and chromatin features which span more than one bin. 
The actual number has been kept low, since at binsize $b=\SI{25}{\kilo\bp}$, 4 bins already correspond to \SI{100}{\kilo\bp}.
Of course, increasing filter width and using more filters can also be combined,
hopefully allowing the  ``wider-longer'' network to capture both correlations
spanning more than one bin and more than one chromatin feature.

Another approach to potentially improve the predictions that goes somewhat into
the direction of the ``wider'' network has been proposed, but not implemented by Farr\'e et al. 
in their paper \cite{Farre2018a}.
ChIP-seq experiments can usually be binned at smaller binsizes than Hi-C data due to the nature of 
the process. 
This can be exploited to capture finer details in the ChIP-seq data without a need for higher (training-)matrix resolutions.
To this end, the initial network can be generalized by binning the ChIP-seq data at $k$ times the bin size of the matrices, 
whereby $k \in \mathbb{N}^{\geq1}$, cf.~\cref{sec:methods:inputBinning} for the technical details.
This yields an input data size of $k \cdot 3w \times n$, which is then again compressed to a $3w \times 1$ vector 
by a 1D convolutional filter with kernel size $n$ and strides $k$. 
For practical reasons, $k=5$ was chosen for the thesis at hand, 
and the results for binsizes $b_{mat}=\SI{25}{\kilo\bp}$, $b_{feat}=\SI{5}{\kilo\bp}$ are shown in \xxx.


\subsubsection{Using a combination of MSE-, TV- and perceptual loss}
In image regression tasks, optimizing for mean squared error is known to produce blurry images,
because it is computed independently for each image pixel, ignoring spatial proximity \cite{Isola2017,Lu2019}.
Another approach to improve the predictions of the basic neural network is thus using a different loss function.

It has been shown that loss functions based on the (multiscale-)structural similarity index (SSIM) \cite{Wang2003}. 
can outperform mean squared error (L2) and mean absolute error (L1) in image regression tasks.
While Zhao et al. used a combination of L1- and multiscale SSIM loss \cite{Zhao2017},
Lu proposed a custom level-weighted SSIM loss \cite{Lu2019}.
The results were better than with L1- or L2 loss alone, but sometimes not much -- depending on the machine learning model in use.

Another type of loss function used in image processing is the so-called perceptual- or perception loss.
The idea here is not to compute L1 or L2 loss directly from the output of the network to be trained,
but instead use a pre-trained loss network to determine structures in ``predicted'' and ``real'' images
and then compute e.\,g. L1 or L2 loss on these structures, \cref{fig:improve:perceptual_loss}.
\begin{figure}[htb]
    \small
    \centering
    %\resizebox{\textwidth}{!}{
    \import{figures/}{explanation_perceptual_loss.pdf_tex}%}
    \caption{perceptual loss}
    \label{fig:improve:perceptual_loss}
\end{figure}
The optimization of the trainable weights can be performed as usual, for example with gradient descent and backpropagation, 
simply keeping the weights of the loss networks constant.
Often, complex image classification networks like VGG-16 \cite{Simonyan2015} are taken as loss network, e.\,g. in the well-known style-transfer network by Johnson et al. \cite{Johnson2016},
because these are known to be good at detecting relevant structures in images.

To check whether the given learning task benefits from using a perceptual loss, a custom combined loss function was generated,
consisting of mean squared error $l_\mathit{MSE}$ between true- and predicted matrices, perceptual loss $l_\mathit{VGG}$ based on VGG-16 and 
total variation loss $l_\mathit{TV}$ to reduce noise in the output while preserving edges \cite{Rudin1992}. 
This choice was inspired by the custom loss function used by Hong et al. in their successful Hi-C super-resolution network DeepHiC \cite{Hong2020},
which is otherwise not similar to the network used here.
In short, the combined loss function $L$ is shown in \cref{eq:combined_loss_short}, see \cref{sec:methods:combined_loss} for details,
\begin{equation}
 L_\mathit{combined} = \lambda_\mathit{MSE} \; l_\mathit{MSE} + \lambda_\mathit{VGG} \; l_\mathit{VGG} + \lambda_\mathit{TV} \; l_\mathit{TV} \label{eq:combined_loss_short}
\end{equation}
with individual loss weights $\lambda$.

Unfortunately, there is no straightforward way for determining the optimal parameters $\lambda$,
and an exhaustive parameter search was infeasible due to the computation time requirements of about 4:30\,min per epoch.
Therefore, only few runs were conducted with different sets of parameters,
and the results for $\lambda_\mathit{MSE} = 0.8999, \lambda_\mathit{VGG}=0.1, \lambda_\mathit{TV}=0.0001$,
which should not be considered optimal, are shown in \cref{sec:results:loss_functions}.

\subsubsection{Using a TAD-based loss function}
Looking at the results obtained from the networks so far, see \xxx, it seemed that highly interacting regions,
especially topologically interacting domains (TADs), were not well predicted and either absent
in the matrix plots or blurred.
Assuming availability of a TAD scoring function $\mathit{tad}(z_\mathit{pred})$, where $z_\mathit{pred}$ is a predicted submatrix,
this might be improved by directly optimizing a loss function as shown in \cref{eq:combined_loss_tad}.
\begin{equation}
 L_\mathit{combined} = \lambda_\mathit{MSE}\;l_\mathit{MSE} + \lambda_\mathit{TAD} \, (\mathit{tad}(z_\mathit{true}) - \mathit{tad}(z_\mathit{pred}))^2 \label{eq:combined_loss_tad}
\end{equation}
However, this approach suffers from several restrictions.
First and foremost, there seems no consensus on the exact definition of TADs, 
and no less than 22 algorithms for TAD detection existed as of 2018 \cite{Dali2017,Zufferey2018}.
Additionally, many of these algorithms have several tuning parameters, are notoriously parameter-dependent
and may not even yield any results if parametrized in an unfavorable way \cite{Zufferey2018}. 
A further restriction results from the context -- since the loss function needs to be optimized,
one needs to be able to compute gradients of it with respect to the network's weights.
Due to their complexity, this is generally very difficult to implement in a computationally efficient way for all known TAD calling algorithms.

To overcome the limitations, a novel loss function based on TAD scores \cite{Crane2015} was developed.
\Cref{fig:improve:tad_score_loss_function} exemplarily shows its basic idea for a $16\times16$ submatrix
with windowsize 4.
\begin{figure}[hbt]
 \begin{minipage}{0.65\textwidth}
   \resizebox{\textwidth}{!}{
    \small
    \import{figures/}{tad_score_loss_function.pdf_tex}}
    \caption{score vector generation for TAD-based loss}
    \label{fig:improve:tad_score_loss_function}
 \end{minipage}\hfill
 \begin{minipage}{0.3\textwidth}
 \scriptsize
  \begin{enumerate}[label=\Alph*:,leftmargin=*]
   \raggedright
    \item first ``diamond''
    \item first 4 diagonals of a $16\times16$ Hi-C matrix, rotated \SI{45}{\deg} counterclockwise
    \item sliding direction for score generation
    \item score vector (mean values within diamonds)
    \item line plot of score vector
    \item possible TAD boundaries
\end{enumerate}
 \end{minipage}
\end{figure}
First, the mean is taken from diamond-shaped (or rhombus-shaped) matrix cutouts along the diagonal, \cref{fig:improve:tad_score_loss_function}\,(A, C),
and stored in a score vector, \cref{fig:improve:tad_score_loss_function}\,(D / E). 
The size of the diamonds, 2 in the figure, is configurable, but a reasonable balance with the submatrix size, i.\,e. the size of the sliding window $w$,
and the expected size of TADs in the matrix must be maintained.
Next, loss is computed by taking the mean squared error between the score vectors of the ``real'' submatrices and the ``predicted'' submatrices, \cref{eq:combined_loss_tad}.

The idea behind the score-based approach is visualized in \cref{fig:improve:tad_score_loss_function}\,(E).
Local minima, i.\,e. dents in the line plot of the score values, \cref{fig:improve:tad_score_loss_function}\,(F),
often correspond with highly interacting regions in the matrix, since the mean of diamonds from \emph{inside} TADs is normally significantly higher than the mean of diamonds \emph{outside} TADs.
Indeed, some TAD calling algorithms like TopDom \cite{Shin2015} and hicFindTADs \cite[W12f.]{Wolff2018} do compute insulation scores -- usually for more than one diamond size -- 
and then use diverse techniques to detect meaningful local minima in the score values.
However, finding meaningful local minima in the given context is still computationally involved,
so it was left to the network to make sense out of the score vectors.
This way, the loss function was well defined, efficiently computable and tensorflow standard functionality could be used to compute gradients with respect to weights.

For the thesis at hand, windowsize $w=80$ and diamond size $ds={12}$ were used at binsizes of \SI{25}{\kilo\bp}.
For technical details please refer to \cref{sec:methods:score_loss}.

\subsubsection{Modifying binsize and windowsize}
In the results presented so far, larger structures were often absent.
In order to improve on this, two approaches were tried.

First, predictions were made at binsizes $b_\mathit{feat} = b_\mathit{mat} = \SI{50}{\kilo\bp}$, 
keeping the windowsize at 80 bins, which then corresponded to \SI{4}{\mega\bp}.
The idea here was to capture predominantly larger structures further away from the diagonal and
then investigate various methods to combine predictions at smaller and larger binsizes.
However, such a merging process was never actually developed,
since the predictions at \SI{50}{\kilo\bp} proved useless, \cref{sec:results:binsize_winsize}.

Unfortunately, doubling the (matrix-)binsizes from 25 to \SI{50}{\kilo\bp} directly leads to a reduction in the number of available training samples by a factor of about two, 
if the windowsizes are kept constant at 80 bins, see \cref{tab:methods:samples}.
For this reason, a second approach was made -- using training samples at $b_\mathit{feat} = b_\mathit{mat} = \SI{25}{\kilo\bp},\;w=80$
and $b_\mathit{feat} = b_\mathit{mat} = \SI{50}{\kilo\bp},\;w=80$ at the same time.
This is easily possible, since the neural network topology only depends on the windowsize \emph{in bins} and the relation $k=b_\mathit{mat}/b_\mathit{feat}$
between the binsizes of features and matrices.
This approach obviously increases the number of training samples,
with the idea of allowing the network itself to figure out how to combine predictions at smaller and larger binsizes.


\begin{itemize}
 \item rationale: smaller binsizes - predict smaller structures, larger binsizes - predict larger structures
 \item then combine the predictions (e.g. sum them up, take the mean or even use a NN)
 \item use trapezoids, i.e. capped larger submatrices and flankingsize smaller than windowsize
 \item rationale: larger windowsize without increasing training time too much 
 \item train on matrices/features with different binsizes in the same training run (e.g. two matrices with 25k, 50k and bin at 25k, 50k or 5k, 10k)
 \end{itemize}
 
 

\subsubsection{DNA sequence as an additional network input branch}
\begin{itemize}
 \item use DNA as an additional input
 \item rationale a): allow the network to figure out true binding sites in conjunction with cs data
 \item rationale b): given the success of pure DNA based methods, allow the network to find yet unknown sequence structure correlations
 \item probably not the most important subsection, leave it out in case of time problems
\end{itemize}

\subsection{Hi-cGAN approach} \label{sec:hi-cGAN}
Because none of the results from the dense neural network approach presented in \cref{sec:results:DNN} were overly convincing,
a second, widely unrelated approach was made.

Since their invention by Goodfellow, Mirza and colleagues \cite{Goodfellow2014, mirza2014},
Generative Adversarial Networks have become increasingly popular for image processing tasks of many kinds,
and especially for image synthesis \cite{Wang2020}. 
Among their strenghts is image synthesis from textual descriptions \cite{Reed2016,Zhang2019c,Zhu2019,Tao2020} --
and from an abstract point of view, this task is not very different from the goal of the thesis at hand.
Considering the chromatin features on the input side as a ``description'' of how the target Hi-C (sub-)matrices should look like,
formulating the goal of the thesis as a cGAN-problem should be possible.
In the following sections, such an approach will be explored.

\subsubsection{General setup of the cGAN approach}
Although numerous variants exist, conditional GANs generally comprise at least two neural networks -- 
a generator $G(x,z)$, which tries to generate realistic outputs from its inputs $x$ and random noise $z$, and a discriminator $D(x,y)$,
which tries to discern true inputs $y$, e.\,g. experimentally derived Hi-C matrices, from generated inputs $G(x,z)$.
The optimal weights for the networks can then be found by searching an equilibrium in a two-player minimax game:
The generator tries to fool the discriminator, while the discriminator tries to detect the generator's fakes, 
see equations \ref{eq:improve:cGAN-simple-loss} and \ref{eq:improve:cGAN-simple-opt} \cite{Isola2017}.
\begin{align}
 L_\mathit{cGAN}(G, D) &= \mathbb{E}_{x,y}[\log D(x,y)] + \mathbb{E}_{x,z}[\log(1-D(x, G(x,z)))] \label{eq:improve:cGAN-simple-loss} \\
 G^* &=  \mathit{arg\,min}_G \mathit{max}_D \; L_\mathit{cGAN}(G, D) \label{eq:improve:cGAN-simple-opt}
\end{align}

Many different layouts and training processes for the Generator and Discriminator networks have been proposed.
For the thesis at hand, the well-known ``pix2pix'' proposal by Isola et al. from 2017 was followed \cite{Isola2017}, 
amended by a convolutional embedding network for the chromatin features, which serve as the conditional input $x$ here.
The overall setup is shown in \cref{fig:improve:cGAN-approach}.
\begin{figure}[hbp]
 \caption{cGAN approach} \label{fig:improve:cGAN-approach}
\end{figure}
Compared to other cGAN architectures, pix2pix is rather simple, but well studied for different applications like label-to-image transfer,
sketch-to-image transfer, grayscale-to-color transformations or image infill tasks \cite{Isola2017}.
Since the problem at hand has likely not been tackled by a specialized GAN yet, 
choosing a ``general-purpose'' cGAN as a starting point seemed reasonable.

For sample generation, we relied on the same method as described for the dense neural network described above
with a few minor adaptations, see \cref{sec:methods:sample_gen_cgan}.

However, since pix2pix operates on images, as its name already implies, 
a method to add the essentially one-dimensional chromatin feature data as conditional input images into the network was needed.
Unfortunately, this task seems to be without examples in literature, so two different approaches were tried,
which will be discussed below in sections \ref{sec:improve:DNN_embedding} and \ref{sec:improve:DNN_embedding}.
Both approaches are somewhat related to the text-encoders used by text-to-image synthesis networks 
\cite{Reed2016b,Xu2018}, but much less sophisticated. 
However, a complex encoding is not needed here, since -- contrary to image captions -- the chromatin features are already in a format that can be processed directly by neural networks.

%State of the art approaches have 80 mio parameters \cite{Brock2019}.
%But these are used for synthesizing images from many different classes, like in imageNet.
%our approach is much more simple



\subsubsection{Using a DNN for feature embedding} \label{sec:improve:DNN_embedding}
First, the deep neural network developed above was employed to turn chromatin features into Hi-C submatrices, which can be seen as grayscale images.
The rationale here was to use the DNN for converting the conditional input into a coarse Hi-C matrix first and then
use the GAN to refine the predictions.
Additionally, the network could be pre-trained as shown above, saving time compared to an embedding that has to be trained alongside the GAN.
Potentially pre-training might also improve stability or enable convergence of the network in general.



\subsubsection{Using a CNN for feature embedding} \label{sec:improve:CNN_embedding}
Second, a short convolutional network was used to embed the one-dimensional chromatin feature vectors in a 2D image.
Here, the idea was to use a fast trainable embedding that keeps the localization information in the chromatin feature data,
has less parameters than a dense embedding and can efficiently be trained along with the rest of the network, allowing for a standalone solution.














