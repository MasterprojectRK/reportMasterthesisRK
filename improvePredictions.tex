\section{Advancing predictions of Hi-C interaction matrices}
In the following subsections, two conceptually different approaches towards the goal of the thesis,
predicting Hi-C matrices from ChIP-seq data, will be explored.
While the first approach is a dense neural network based on work by Farr\'e et al. \cite{Farre2018a},
the second is a novel method based on conditional generative adversarial networks.

\subsection{Dense Neural Network approach}\label{sec:improve:DNNapproach}
In their 2008 paper \cite{Farre2018a}, Pau Farr\'e, Alexandre Heurtau, Olivier Cuvier and Eldon Emberly
propose a combination of a 1D convolutional filter with a three-layer dense neural network 
which already fulfills most goals of this thesis with some exceptions regarding data formats and preprocessing.
This thesis tries to build on the success of their method by extending the comparatively simple neural network
in various ways, modifying the binsizes of the Hi-C matrices and changing the learning process.
As a start, the basic network has been rebuilt and used on well-known data from human cell lines GM12878 and K562, cf. \cref{sec:methods:input_data}.

\subsubsection{Basic network setup} \label{sec:improve:basicNetwork}
The basic network setup taken over from Farr\'e et al. \cite{Farre2018a} is shown in simplied form in \cref{fig:improve:priciple_basic_dnn},
see \cref{sec:methods:basicSetup} for technical details.
\begin{figure}[hbp]
    \small
    \centering
    \resizebox{\textwidth}{!}{
    \import{figures/}{explanation_dnn_hic.pdf_tex}}
    \caption{Principle of basic dense neural network}
    \label{fig:improve:priciple_basic_dnn}
\end{figure}

Since the network implements a supervised learning technique,
it requires two kinds of inputs for training -- ChIP-seq data of the chosen chromatin factors and
target Hi-C matrices for each training chromosome.
However, it is generally infeasible to learn Hi-C matrices for complete chromosomes at once with machine learning approaches, 
because the latter heavily depend on availability of training data.
The target matrices are thus taken as submatrices of size $w \times w$ 
with fixed windowsize $w$, centered at the diagonal of the 
original Hi-C matrices, \cref{fig:improve:priciple_basic_dnn} top.
The ChIP-seq data of $n$ chromatin features is taken as $3w \times n$ subarray of the original array,
whereby the middle $w$ bins are aligned with the position of the submatrix,
the first $w$ bins correspond to the left flanking region and the last $w$ bins correspond to 
the right flanking region of the current submatrix region, \cref{fig:improve:priciple_basic_dnn} bottom. 
Training samples are then obtained from the input data by sliding 
the input windows along the diagonal of the target Hi-C matrix. 
For the technical details of the sample generation process, see \cref{sec:methods:sample_gen}.

Within the network, a 1D convolutional filter compresses the $3w \times n$ input arrays to 1D vectors
of size $3w \times 1$, and four dense layers further process the compressed input, \cref{fig:improve:priciple_basic_dnn} middle.
The number of neurons in the last dense layer corresponds to the number of bins
in the upper triangular part of the target submatrix, i.\,e. it consists of $(w \cdot (w+1))/2$ neurons, \cref{fig:improve:priciple_basic_dnn} top, 
exploiting the symmetry of Hi-C matrices. 
For implementation details, please refer to \cref{sec:methods:basicSetup}.

Training of the network is performed by minimizing the mean squared error of the predicted matrix
versus the target Hi-C matrix using stochastic gradient descent, cf. \cref{sec:methods:basicSetup}.

Farr\'e et al. propose a windowsize of $w=80$ at $b_{feat} = b_{mat} = \SI{10}{\kilo\bp}$.
However, larger binsizes of $b_{feat} = b_{mat} = \SI{25}{\kilo\bp}$ were found beneficial for 
most of the data used throughout this master thesis.
Additionally, larger binsizes allow for a higher coverage of the target matrix at the same windowsize,
because the windowsize is specified in bins, and obviously $10\, w < 25\, w$.
Results for both binsize 10 and \SI{25}{\kilo\bp} are shown in \cref{sec:initialDNNresults}.

The network layout shown above is quite simple, and immediately offers some opportunities
for expansion, partially already proposed in the original paper \cite{Farre2018a}.
These will be explored below.

\subsubsection{Modifying the convolutional part of the network} \label{sec:improve:convolution_extensions}
One starting point for modifying the neural network is its convolutional part.

With only a single 1D convolutional filter in one layer, the network might have difficulties capturing complex relationships 
between Hi-C interaction counts and more than one of the chromatin features.
For this reason, an extended ``longer'' network was created, 
comprising three 1D convolutional filter layers with 16, 8 and 4 filters, respectively, replacing the single
1D-convolution in \cref{fig:improve:priciple_basic_dnn}, lower left, cf. \cref{sec:methods:variants}.
This is still a comparatively low number of layers and filters,
but the choice seemed justified in order to avoid overfitting to the low-dimensional input.
The results are shown in \cref{sec:results:wider-longer-etc}, especially figures \ref{fig:results:longerDNN_pearson} and \ref{fig:results:longer_matrices}.

Next, a ``wider'' network was created, featuring the same setup as the basic network
except the width of the filter kernel, which was set to 4 instead of 1.
The idea here was to allow the network to capture correlations between Hi-C interaction counts
and chromatin features which span more than one bin. 
The actual number has been kept low, since at binsize $b=\SI{25}{\kilo\bp}$, 4 bins already correspond to \SI{100}{\kilo\bp}.
However, the results were not as expected, cf. \cref{sec:results:wider-longer-etc}, especially figures \ref{fig:results:widerDNN_pearson} and \ref{fig:results:wider_matrices}.
Of course, increasing filter width and using more filters can also be combined,
hopefully allowing the  ``wider-longer'' network to capture both correlations
spanning more than one bin and more than one chromatin feature.
The results for this combined approach are shown in \cref{sec:results:wider-longer-etc}, especially figures \ref{fig:results:wider-longerDNN_pearson} and \ref{fig:results:wider_matrices}.

Another approach to potentially improve the predictions that goes somewhat into
the direction of the ``wider'' network has been proposed, but not implemented by Farr\'e et al. 
in their paper \cite{Farre2018a}.
ChIP-seq experiments can usually be binned at smaller binsizes than Hi-C data due to the nature of 
the process. 
This can be exploited to capture finer details in the ChIP-seq data without a need for higher (training-)matrix resolutions.
To this end, the initial network can be generalized by binning the ChIP-seq data at $k$ times the bin size of the matrices, 
whereby $k \in \mathbb{N}^{\geq1}$, cf.~\cref{sec:methods:inputBinning} for the technical details.
This yields an input data size of $k \cdot 3w \times n$, which is then again compressed to a $3w \times 1$ vector 
by a 1D convolutional filter with kernel size $n$ and strides $k$. 
For practical reasons, $k=5$ was chosen for the thesis at hand, 
and the results for binsizes $b_{mat}=\SI{25}{\kilo\bp}$, $b_{feat}=\SI{5}{\kilo\bp}$ are shown in \cref{sec:results:wider-longer-etc},
especially figures \ref{fig:results:25k5DNN_pearson} and \ref{fig:results:25k5_matrices}.


\subsubsection{Using a combination of MSE-, TV- and perceptual loss} \label{sec:improve:combined_loss}
In image regression tasks, optimizing for mean squared error is known to produce blurry images,
because it is computed independently for each image pixel, ignoring spatial proximity \cite{Isola2017,Lu2019}.
And indeed, both the predictions from the initial and the extended network according to sections \ref{sec:improve:basicNetwork} and \ref{sec:improve:convolution_extensions} 
suffered from blurriness. 
To improve on this, investigations with modified loss functions were made. 

It has been shown that loss functions based on the (multiscale-)structural similarity index (SSIM) \cite{Wang2003}. 
can outperform mean squared error (L2) and mean absolute error (L1) in image regression tasks.
While Zhao et al. used a combination of L1- and multiscale SSIM loss \cite{Zhao2017},
Lu proposed a custom level-weighted SSIM loss \cite{Lu2019}.
The results were better than with L1- or L2 loss alone, but sometimes not much -- depending on the machine learning model in use.

Another type of loss function used to produce sharp images is the so-called perceptual- or perception loss.
The idea here is not to compute L1- or L2 loss directly from the output of the network to be trained,
but instead use a pre-trained loss network to determine structures in ``predicted'' and ``real'' images
and then compute e.\,g. L1- or L2 loss on these structures, \cref{fig:improve:perceptual_loss}.
\begin{figure}[hbt]
    \small
    \centering
    %\resizebox{\textwidth}{!}{
    \import{figures/}{explanation_perceptual_loss.pdf_tex}%}
    \caption{perceptual loss}
    \label{fig:improve:perceptual_loss}
\end{figure}

The optimization of the target network's trainable weights can be performed as usual, for example with gradient descent and backpropagation, 
simply keeping the weights of the loss networks constant.
Often, complex image classification networks like VGG-16 \cite{Simonyan2015} are taken as loss network, e.\,g. in the well-known style-transfer network by Johnson et al. \cite{Johnson2016},
because these are known to be good at detecting relevant structures in images.

To check whether the given learning task benefits from using a perceptual loss, a custom combined loss function was generated,
consisting of mean squared error $L_\mathit{MSE}$ between true- and predicted matrices, perceptual loss $L_\mathit{VGG}$ based on VGG-16 and 
total variation loss $L_\mathit{TV}$ to reduce noise in the output while preserving edges \cite{Rudin1992}. 
This choice was inspired by the custom loss function used by Hong et al. in their successful Hi-C super-resolution network DeepHiC \cite{Hong2020},
which is otherwise not similar to the network used here.
In short, the combined loss function $L$ is shown in \cref{eq:combined_loss_short}. Here, the $\lambda$ are individual loss weights, see \cref{sec:methods:combined_loss} for details.
\begin{equation}
 L_\mathit{combined} = \lambda_\mathit{MSE} \; L_\mathit{MSE} + \lambda_\mathit{VGG} \; L_\mathit{VGG} + \lambda_\mathit{TV} \; L_\mathit{TV} \label{eq:combined_loss_short}
\end{equation}

Unfortunately, there is no straightforward way for determining the optimal parameters $\lambda$,
and an exhaustive parameter search was infeasible due to the computation time requirements of about 4:30\,min per epoch.
Therefore, only few runs were conducted with different sets of parameters,
and the results for $\lambda_\mathit{MSE} = 0.8999, \lambda_\mathit{VGG}=0.1, \lambda_\mathit{TV}=0.0001$,
which should not be considered optimal, are shown in \cref{sec:results:loss_functions}.

\subsubsection{Using a TAD-based loss function} \label{sec:improve:TAD_loss}
Looking at the results obtained from the networks so far, see \xxx, it seemed that highly interacting regions,
especially topologically interacting domains (TADs), were not well predicted and either absent
in the matrix plots or blurred.
Assuming availability of a TAD scoring function $\mathit{tad}(z_\mathit{pred})$, where $z_\mathit{pred}$ is a predicted submatrix,
this might be improved by directly optimizing a loss function as shown in \cref{eq:combined_loss_tad}.
\begin{equation}
 L_\mathit{combined} = \lambda_\mathit{MSE}\;L_\mathit{MSE} + \lambda_\mathit{TAD} \, (\mathit{tad}(z_\mathit{true}) - \mathit{tad}(z_\mathit{pred}))^2 \label{eq:combined_loss_tad}
\end{equation}
However, this approach suffers from several restrictions.
First and foremost, there seems no consensus on the exact definition of TADs, 
and no less than 22 algorithms for TAD detection existed as of 2018 \cite{Dali2017,Zufferey2018}.
Additionally, many of these algorithms have several tuning parameters, are notoriously parameter-dependent
and may not even yield any results if parametrized in an unfavorable way \cite{Zufferey2018}. 
A further restriction results from the context -- since the loss function needs to be optimized,
one needs to be able to compute gradients of it with respect to the network's weights.
Due to their complexity, this is generally very difficult to implement in a computationally efficient way for all known TAD calling algorithms.

To overcome the limitations, a novel loss function based on TAD scores \cite{Crane2015} was developed.
\Cref{fig:improve:tad_score_loss_function} exemplarily shows its basic idea for a $16\times16$ submatrix
with windowsize 4.
\begin{figure}[hbt]
 \begin{minipage}{0.65\textwidth}
   \resizebox{\textwidth}{!}{
    \small
    \import{figures/}{tad_score_loss_function.pdf_tex}}
    \caption{score vector generation for TAD-based loss}
    \label{fig:improve:tad_score_loss_function}
 \end{minipage}\hfill
 \begin{minipage}{0.3\textwidth}
 \scriptsize
  \begin{enumerate}[label=\Alph*:,leftmargin=*]
   \raggedright
    \item first ``diamond''
    \item first 4 diagonals of a $16\times16$ Hi-C matrix, rotated \SI{45}{\deg} counterclockwise
    \item sliding direction for score generation
    \item score vector (mean values within diamonds)
    \item line plot of score vector
    \item possible TAD boundaries
\end{enumerate}
 \end{minipage}
\end{figure}
First, the mean is taken from diamond-shaped (or rhombus-shaped) matrix cutouts along the diagonal, \cref{fig:improve:tad_score_loss_function}\,(A, C),
and stored in a score vector, \cref{fig:improve:tad_score_loss_function}\,(D / E). 
The size of the diamonds, 2 in the figure, is configurable, but a reasonable balance with the submatrix size, i.\,e. the size of the sliding window $w$,
and the expected size of TADs in the matrix must be maintained.
Next, loss is computed by taking the mean squared error between the score vectors of the ``real'' submatrices and the ``predicted'' submatrices, \cref{eq:combined_loss_tad}.

The idea behind the score-based approach is visualized in \cref{fig:improve:tad_score_loss_function}\,(E).
Local minima, i.\,e. dents in the line plot of the score values, \cref{fig:improve:tad_score_loss_function}\,(F),
often correspond with highly interacting regions in the matrix, since the mean of diamonds from \emph{inside} TADs is normally significantly higher than the mean of diamonds \emph{outside} TADs.
Indeed, some TAD calling algorithms like TopDom \cite{Shin2015} and hicFindTADs \cite[W12f.]{Wolff2018} do compute insulation scores -- usually for more than one diamond size -- 
and then use diverse techniques to detect meaningful local minima in the score values.
However, finding meaningful local minima in the given context is still computationally involved,
so it was left to the network to make sense out of the score vectors.
This way, the loss function was well defined, efficiently computable and tensorflow standard functionality could be used to compute gradients with respect to weights.

For the thesis at hand, windowsize $w=80$ and diamond size $ds={12}$ were used at binsizes of \SI{25}{\kilo\bp}.
For technical details please refer to \cref{sec:methods:score_loss}.

\subsubsection{Modifying binsize and windowsize}
In the results presented so far, larger structures were often absent.
In order to improve on this, two approaches were tried.

First, predictions were made at binsizes $b_\mathit{feat} = b_\mathit{mat} = \SI{50}{\kilo\bp}$, 
keeping the windowsize at 80 bins, which then corresponded to \SI{4}{\mega\bp}.
The idea here was to capture predominantly larger structures further away from the diagonal and
then investigate various methods to combine predictions at smaller and larger binsizes.
However, such a merging process was never actually developed,
since the predictions at \SI{50}{\kilo\bp} alone were not good enough, \cref{sec:results:binsize_winsize}.

Unfortunately, doubling the (matrix-)binsizes from 25 to \SI{50}{\kilo\bp} directly leads to a reduction in the number of available training samples by a factor of about two, 
if the windowsizes are kept constant at 80 bins, see \cref{tab:methods:samples}. 
This might also be one of the causes why predictions at \SI{50}{\kilo\bp} proved useless.
For this reason, a second approach was made -- using training samples at $b_\mathit{feat} = b_\mathit{mat} = \SI{25}{\kilo\bp},\;w=80$
and $b_\mathit{feat} = b_\mathit{mat} = \SI{50}{\kilo\bp},\;w=80$ at the same time.
This is easily possible, since the neural network topology only depends on the windowsize \emph{in bins} and the relation $k=b_\mathit{mat}/b_\mathit{feat}$
between the binsizes of features and matrices.
This approach obviously increases the number of training samples,
with the idea of allowing the network itself to figure out how to combine predictions at smaller and larger binsizes.


\begin{itemize}
 \item use trapezoids, i.e. capped larger submatrices and flankingsize smaller than windowsize
 \item rationale: larger windowsize without increasing training time too much
 \end{itemize}
 
 

\subsubsection{DNA sequence as an additional network input branch}
\begin{itemize}
 \item use DNA as an additional input
 \item rationale a): allow the network to figure out true binding sites in conjunction with cs data
 \item rationale b): given the success of pure DNA based methods, allow the network to find yet unknown sequence structure correlations
 \item probably not the most important subsection, leave it out in case of time problems
\end{itemize}

\subsection{Hi-cGAN approach} \label{sec:improve:Hi-cGAN}
Because none of the results from the dense neural network approach presented in \cref{sec:results:DNN} were overly convincing,
a second, widely unrelated approach was made.

Since their invention by Goodfellow, Mirza and colleagues \cite{Goodfellow2014, mirza2014},
Generative Adversarial Networks have become increasingly popular for image processing tasks of many kinds,
and especially for image synthesis \cite{Wang2020}. 
Among their strenghts is image synthesis from textual descriptions \cite{Reed2016,Zhang2019c,Zhu2019,Tao2020} --
and from an abstract point of view, this task is not very different from the goal of the thesis at hand.
Considering the chromatin features on the input side as a ``description'' of how the target Hi-C (sub-)matrices should look like,
formulating the goal of the thesis as a cGAN-problem should be possible.
In the following sections, such an approach will be explored.

\subsubsection{General setup of the cGAN approach}
Although numerous variants exist, conditional GANs generally comprise at least two neural networks -- 
a generator $G(x,z)$, which tries to generate realistic outputs from its inputs $x$ and random noise $z$, and a discriminator $D(x,y)$,
which tries to discern true inputs $y$, e.\,g. experimentally derived Hi-C matrices, from generated inputs $G(x,z)$.
The optimal weights for the networks can then be found by searching an equilibrium in a two-player minimax game:
The generator tries to fool the discriminator, while the discriminator tries to detect the generator's fakes, 
see equations \ref{eq:improve:cGAN-simple-loss} and \ref{eq:improve:cGAN-simple-opt} \cite{Isola2017}.
\begin{align}
 L_\mathit{cGAN}(G, D) &= \mathbb{E}_{x,y}[\log D(x,y)] + \mathbb{E}_{x,z}[\log(1-D(x, G(x,z)))] \label{eq:improve:cGAN-simple-loss} \\
 G^* &=  \mathit{arg\,min}_G \mathit{max}_D \; L_\mathit{cGAN}(G, D) \label{eq:improve:cGAN-simple-opt}
\end{align}

Many different layouts and training processes for the Generator and Discriminator networks have been proposed.
For the thesis at hand, the well-known ``pix2pix'' proposal by Isola et al. from 2017 was followed \cite{Isola2017}, 
amended by a convolutional embedding network for the chromatin features, which serve as the conditional input $x$ here.
The overall setup is shown in \cref{fig:improve:cGAN-approach} and will be explained in more detail below.
\begin{figure}[htbp]
 \import{figures/}{Hi-cGAN.pdf_tex}
 \caption{cGAN approach} \label{fig:improve:cGAN-approach}
\end{figure}
The generator architecture is based the well known U-Net architecture due to Ronneberger, Fischer and Brox \cite{Ronneberger2015},
while the discriminator is implemented as a patchGAN-discriminator developed by Isola et al. especially for pix2pix \cite{Isola2017}.
This type of discriminator splits the images into patches and tries to decide which of them are real and which are fake, using convolutions.
Note that pix2pix does not explicitly add noise $z$, but by design only relies on dropout layers for that purpose. 

For the thesis at hand, few modifications were made to the actual pix2pix network.
Since Hi-C matrices are symmetric by definition, symmetry of the outputs was enforced
by adding additional layers to the network at the appropriate places, see \cref{sec:methods:cGAN_initial} for details.
Furthermore, some layers in the generator and discriminator were made optional to allow processing smaller images of sizes $64\times64$
and $128\times128$ aside the $256\times256$-images of the original implementation, again refer to \cref{sec:methods:cGAN_initial} for details.

For sample generation, we relied on the same method as described for the dense neural network described above
with a few minor adaptations, see \cref{sec:methods:sample_gen_cgan}.
However, since pix2pix operates on images, as its name already implies, 
a method to add the essentially one-dimensional chromatin feature data as conditional input images into the network was needed.
Unfortunately, this task seems to be without examples in literature, so two different approaches were tried,
which will be discussed below in sections \ref{sec:improve:DNN_embedding} and \ref{sec:improve:DNN_embedding}.
Both approaches are distantly related to the text-encoders used by text-to-image synthesis networks 
\cite{Reed2016b,Xu2018}, but much less sophisticated. 
However, a complex encoding is not needed here, since -- contrary to image captions -- the chromatin features are already in a format that can be processed directly by neural networks.

Many ways for training a cGAN exist, and achieving a stable, converging training process can be tricky.
For the thesis at hand, we therefore relied on the  extended loss function proposed by Isola et al. \cite{Isola2017}, 
amended by a TV loss function $L_\mathit{TV}$ for noise reduction, \cref{eq:improve:cGAN_loss}.
\begin{align}
 L_\mathit{total} = \lambda_\mathit{cGAN} \; L_\mathit{cGAN}(G,D) + \lambda_\mathit{MAE}L_\mathit{MAE}(G) + \lambda_\mathit{TV}L_\mathit{TV}(G) \label{eq:improve:cGAN_loss}
\end{align}
Here, $L_\mathit{MAE}$ is the mean absolute error (L1 error) between the generated output $G(x,z)$ and the true Hi-C submatrices $y$ (as grayscale images), 
and $l_\mathit{TV}$ is a total variation loss as in \cref{eq:combined_loss_short} and \cref{eq:methods:tv}.
The original idea behind using mean absolute error and PatchGAN in combination is that optimizing for MAE 
will minimize low-frequency errors, while optimizing the PatchGAN-loss with its small patches helps reducing high-frequency errors \cite{Isola2017}.
The TV loss has been added for edge-aware noise removal, in line with other works in the field \cite{Hong2020}, cf.~\cref{sec:improve:combined_loss}.

Finally, the loss function was optimized with the Adam optimizer,
alternately training discriminator and generator,
see \cref{sec:methods:cGAN_initial} for details.

Compared to other cGAN architectures, pix2pix is rather simple, but well studied for different applications like label-to-image transfer,
sketch-to-image transfer, grayscale-to-color transformations or image infill tasks \cite{Isola2017}.
Since the problem at hand has likely not been tackled by a tailor-made GAN yet, 
choosing a ``general-purpose'' cGAN as a starting point seemed reasonable.
Another advantage towards pix2pix, and U-Net architectures in general, 
is that they can achieve good performance even with comparatively few training samples \cite{Isola2017, Ronneberger2015}.

\subsubsection{Using a DNN for feature embedding} \label{sec:improve:DNN_embedding}
The embedding network required for processing the conditional inputs
has on obvious mandatory property: it must be capable of embedding the input of shape $(3w,n)$ 
into a 2D grayscale image of shape $(w,w,1)$.
Naturally, this can be achieved by using the dense neural network explored above
and reshaping its ``upper triangular'' output vector back into a symmetric ``image'' tensor with the required shape.

The rationale here was to first use the DNN to get a coarse estimate of the predicted matrix,
and then the cGAN to refine the results, somewhat similar to the two-stage approach by Zhang et al. \cite{Zhang2019c},
albeit much less sophisticated. 
Naturally, this approach also allows to pre-train the dense network as shown above and then use transfer learning
to provide better starting values for the embedding network, potentially improving both stability and convergence speed
of the cGAN network.

A disadvantage of the dense network approach is that the number of neurons in its output layer quadratically depends on the windowsize $w$.
Taken together with the three fully connected layers underneath, this leads to a superlinear increase in the number of parameters along $w$,
further aggravated by the fact that the cGAN requires $w$ to be powers of two, cf. \cref{sec:methods:cGAN_initial} and  
\ref{sec:methods:dnn-embedding} (\cref{tab:methods:embedding_network_params}, p.~\pageref{tab:methods:embedding_network_params}).
The DNN embedding has thus only been explored for $w=64$, both with and without pretraining. 
The results are to be found in \cref{sec:results:cgan_dnn}.

\subsubsection{Using a CNN for feature embedding} \label{sec:improve:CNN_embedding}
Since the results from the DNN embedding were not convincing, another approach based on convolutional layers was created.
Here, the idea was to have a trainable embedding that keeps the localization information in the chromatin feature data,
has less parameters than a dense embedding and can efficiently be trained along with the rest of the network, allowing for a standalone solution.

Since no example for such an embedding was found in literature, a first try was made with a simple 8-layer convolutional network.
The complete setup is shown in \cref{sec:methods:cnn-embedding} (\cref{fig:methods:GAN_arch:embedding_network}, p.~\pageref{fig:methods:GAN_arch:embedding_network}).
Compared to the dense approach, the number of parameters in the CNN embedding is widely independent of the windowsize and 
stays between 4.24 million and 4.29 million for the tested windowsizes 64, 128 and 256, cf. \cref{tab:methods:embedding_network_params} (p.~\pageref{tab:methods:embedding_network_params}).

\subsubsection{Using DNN and CNN embedding for generator and discriminator}











